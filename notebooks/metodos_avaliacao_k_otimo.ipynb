{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8fcab3-e36b-4926-9a41-24f0ffaf400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from IPython.display import display,HTML\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa6851-8321-4c4d-95a1-f99ee30201a2",
   "metadata": {},
   "source": [
    "### Detalhes do Dataset utilizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89b13fc-c088-4b91-8bde-c5b95c2f68f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/dados_k_means_3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m MAX_CLUSTERS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[0;32m      7\u001b[0m PATH_TO_DATASET\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/dados_k_means_3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m dfArquivo\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_TO_DATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m dfArquivo \u001b[38;5;241m=\u001b[39m dfArquivo\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEN1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Excluir coluna do identificador censitário\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\DNL\\mestrado\\IndicadoresCompostos\\ppginf-otimizacao-k-means\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\DNL\\mestrado\\IndicadoresCompostos\\ppginf-otimizacao-k-means\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Documents\\DNL\\mestrado\\IndicadoresCompostos\\ppginf-otimizacao-k-means\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\DNL\\mestrado\\IndicadoresCompostos\\ppginf-otimizacao-k-means\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\Documents\\DNL\\mestrado\\IndicadoresCompostos\\ppginf-otimizacao-k-means\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/dados_k_means_3.csv'"
     ]
    }
   ],
   "source": [
    "#configurar tema dos gráficos\n",
    "sns.set_theme()\n",
    "# abrir dataset com os indicadores\n",
    "MIN_CLUSTERS=2\n",
    "MAX_CLUSTERS=15\n",
    "\n",
    "PATH_TO_DATASET=\"../dataset/dados_k_means_3.csv\"\n",
    "dfArquivo=pd.read_csv(PATH_TO_DATASET,sep=\";\")\n",
    "dfArquivo = dfArquivo.drop([\"EN1.1\"],axis=1)\n",
    "\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "dfArquivo.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346bb19d-fb45-4ab7-a1b3-93590d52a963",
   "metadata": {},
   "source": [
    "### Utilização do GAP Statistic para determinar o número ótimo de clusters\n",
    "\n",
    "O Gap Statistic é uma medida estatística usada para determinar o número ideal de clusters em uma análise de agrupamento (clustering). Ele compara a dispersão dentro dos clusters com a dispersão esperada em um conjunto de dados aleatório com o mesmo número de clusters. Uma lacuna maior indica uma boa separação entre os clusters e sugere que o número correspondente de clusters é uma escolha apropriada.\r\n",
    "\r\n",
    "A interpretação do Gap Statistic no contexto de encontrar o número ideal de clusters é a seguin:\n",
    "\n",
    "\r\n",
    "\r\n",
    "Gap Estatisticamente Significa:\n",
    "\n",
    "vo: Se o Gap Statistic para um determinado número de clusters for significativamente maior do que para o número de clusters adjacentes, isso sugere que o número de clusters é apropriado para a estrutura subjacente dos dad\n",
    "s.\r\n",
    "\r\n",
    "Gap Estatisticamente não Significa\n",
    "\n",
    "tivo: Se o Gap Statistic não mostrar um aumento significativo para um determinado número de clusters em comparação com o próximo, pode indicar que os dados não contêm estrutura de cluster substancial.\r\n",
    "\r\n",
    "Em resumo, ao analisar o gráfico Gap Statistic vs. K, você procura um ponto onde a lacuna entre os valores da estatística Gap seja maximizada, indicando que adicionar mais clusters não melhora substancialmente a qualidade da clusterização. Isso ajuda a determinar o número ótimo de clusters para o seu conjunto de dados.e dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ae04b-3692-4770-be34-0f240163bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar a quantidade ótima de clusters usando GAP Statitisc\n",
    "\n",
    "def gap_statistic_method(data, nrefs=3,min_clusters=2, max_clusters=15):\n",
    "    \"\"\"\n",
    "    Calcular a quantidade ótima de clusters utilizando o método Gap Statistic \n",
    "    Params:\n",
    "        data: Conjunto de dados (DataFrame ou ndarray)\n",
    "        nrefs: Quantidade de conjuntos de referência que serão criados\n",
    "        maxClusters: Número máximo de clusters que serão testados\n",
    "    Return: (melhor_k, resultsDf)\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values \n",
    "        \n",
    "    gaps = np.zeros((len(range(min_clusters, max_clusters)),))\n",
    "    resultsDf = pd.DataFrame({'qtd_clusters':[], 'gap':[]})\n",
    "    \n",
    "    for gap_index, k in enumerate(range(min_clusters, max_clusters)):\n",
    "        # Acumulador dos resultados de dispersão\n",
    "        refDisps = np.zeros(nrefs)\n",
    "        \n",
    "        # Para n referências, gere uma amostra aleatória e execute o algoritmo K-means, \n",
    "        # obtendo a dispersão resultante de cada iteração.\n",
    "        for i in range(nrefs):\n",
    "            # Criar conjunto aleatório de referência\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Aplicar o K-means no conjunto de referência\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "            \n",
    "        # Aplicar o K-means no conjunto de dados original e calculaar a dispersão\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        origDisp = km.inertia_\n",
    "        \n",
    "        # Calcular o GAP Statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "        \n",
    "        # Armazenar o resultado do GAP Statistic\n",
    "        gaps[gap_index] = gap\n",
    "        resultsDf.loc[gap_index] = [k, gap] \n",
    "        \n",
    "    indice_melhor_k = gaps.argmax()\n",
    "    return resultsDf.iloc[indice_melhor_k][\"qtd_clusters\"],indice_melhor_k, resultsDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faeba6e-8540-4ddb-8d4a-a12a5e1dfd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definir o conjunto de dados para avaliação do GAP Statistic\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "\n",
    "# Executar o GAP Statistic para determinar o número ótimo de clusters\n",
    "melhor_k,indice_maior_gap, resultsDf = gap_statistic_method(dados.values,\n",
    "                                                          min_clusters=MIN_CLUSTERS,\n",
    "                                                          max_clusters=MAX_CLUSTERS)\n",
    "\n",
    "# Plotagem dos resultados\n",
    "sns.lineplot(x=resultsDf[\"qtd_clusters\"], y=resultsDf[\"gap\"], marker='o')\n",
    "\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Gap Statistic')\n",
    "plt.title('Avaliação de Clusters com Gap Statistic')\n",
    "plt.axvline(x=melhor_k, color='red', linestyle='--', label=f'Número ideal de clusters: {melhor_k}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Imprime o número ideal de clusters e os valores do Gap Statistic\n",
    "print(\"Número ideal de clusters:\", melhor_k)\n",
    "print(\"Valores do Gap Statistic:\\n\\n\", resultsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d63f32-3dd7-4589-b8be-f07289703710",
   "metadata": {},
   "source": [
    "### Utilização do Método de Cotovelo para determinar o número ótimo de clusters\n",
    "\n",
    "O método do cotovelo (Elbow Method) é uma técnica simples e comum para determinar o número ideal de clusters em um conjunto de dados. \n",
    "Consiste em executar o algoritmo de clustering (por exemplo, K-means) para diferentes valores de K e plotar a soma dos quadrados das distâncias intra-cluster em relação ao número de clusters. \n",
    "\n",
    "O ponto de \"cotovelo\" no gráfico é geralmente considerado como o número ideal de clusters.\n",
    "\n",
    "A lógica por trás do Método do Cotovelo é que, à medida que o número de clusters aumenta, a soma dos quadrados das distâncias intra-cluster diminui. No entanto, em um certo ponto, adicionar mais clusters não leva a uma redução significativa na soma dos quadrados das distâncias intra-cluster. Este ponto é comumente referido como o ponto de \"cotovelo\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac8b12-a524-4408-a8d9-32ebdfd570fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar a quantidade ótima de clusters usando o Método de Cotovelo (Elbow Method)\n",
    "def elbow_method(data, min_clusters=2, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Implementação do método de cotovelo para encontrar o número ideal de clusters.\n",
    "    \n",
    "    Params:\n",
    "        data: ndarray de forma (n_samples, n_features)\n",
    "            O conjunto de dados a ser agrupado.\n",
    "        max_clusters: int, opcional (padrão=10)\n",
    "            O número máximo de clusters a serem testados.\n",
    "    \n",
    "    Return:\n",
    "        (indice_maior_elbow, resultsDf)\n",
    "    \"\"\"\n",
    "    distortions = []  # Armazena a soma dos quadrados das distâncias intra-cluster\n",
    "    resultsDf = pd.DataFrame({'qtd_clusters':[], 'distortions':[]})\n",
    "    \n",
    "    for i,k in enumerate(range(min_clusters, max_clusters + 1)):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(data)\n",
    "        \n",
    "        # Armazenar o resultado do soma dos quadrados das distâncias intra-cluster\n",
    "        distortions.append(kmeans.inertia_) \n",
    "        resultsDf.loc[i] = [k, kmeans.inertia_] \n",
    "    \n",
    "    # Encontrar o ponto de cotovelo (método mais simples - procurando a maior inclinação)\n",
    "    differences = np.diff(distortions)\n",
    "    indice_melhor_k = np.argmax(differences)\n",
    "    \n",
    "    return resultsDf.iloc[indice_melhor_k][\"qtd_clusters\"],indice_melhor_k, resultsDf, differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851868ae-0b0e-49c6-8304-d684791d219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definir o conjunto de dados para avaliação do método de cotovelo\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "\n",
    "# Executar método de cotovelo para determinar o número ótimo de clusters\n",
    "melhor_k,elbow_index, resultsDf,differences = elbow_method(dados,\n",
    "                                                          min_clusters=MIN_CLUSTERS,\n",
    "                                                          max_clusters=MAX_CLUSTERS)\n",
    "\n",
    "sns.lineplot(x=resultsDf[\"qtd_clusters\"], y=resultsDf[\"distortions\"], marker='o')\n",
    "\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Soma dos quadrados das distâncias intra-cluster')\n",
    "plt.title('Método do Cotovelo')\n",
    "plt.axvline(x=melhor_k, color='red', linestyle='--', label=f'Número ideal de clusters: {melhor_k}')  # Adiciona uma linha vertical\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Imprime o número ideal de clusters e os valores do Gap Statistic\n",
    "print(\"Número ideal de clusters:\", melhor_k)\n",
    "print(\"Valores do Elbow Method:\\n\\n\", resultsDf,\"\\nDiferenças: \\n\",pd.DataFrame(differences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e2506-90f7-479a-8fe2-deb0a4df80fe",
   "metadata": {},
   "source": [
    "### Utilização do Método Silhouette Score para determinar o número ótimo de clusters\n",
    "\n",
    "O Silhouette Score é uma medida que avalia a qualidade dos clusters formados por um algoritmo de clustering, como o K-means. \n",
    "Ele fornece uma pontuação para cada ponto de dados, indicando o quão bem esse ponto é atribuído ao seu cluster e quão distante ele está dos outros clusters. \n",
    "O Silhouette Score varia de -1 a 1, onde valores mais altos indicam uma melhor separação entre os clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b263271-c514-4615-b31e-6845bfc8f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score_method(data, min_clusters=2 ,max_clusters=15):\n",
    "    \"\"\"\n",
    "    Implementação do Silhouette Score para determinar o número ideal de clusters usando K-means.\n",
    "    \n",
    "    Params:\n",
    "        data: ndarray de forma (n_samples, n_features)\n",
    "            O conjunto de dados a ser agrupado.\n",
    "        min_clusters: int, opcional (padrão=3)\n",
    "            O número mínimo de clusters a serem testados.\n",
    "        max_clusters: int, opcional (padrão=10)\n",
    "            O número máximo de clusters a serem testados.\n",
    "    \n",
    "    Return:\n",
    "        indice_maior_silhueta: int\n",
    "            O número ideal de clusters com base no Silhouette Score.\n",
    "        resultsDf: DataFrame\n",
    "            Dataframe contendo os Silhouette Scores para cada número de clusters testado.\n",
    "    \"\"\"\n",
    "    \n",
    "    silhouette_scores = []\n",
    "    resultsDf = pd.DataFrame({'qtd_clusters':[], 'silhouette_score':[]})\n",
    "    \n",
    "    for i,k in enumerate(range(min_clusters, max_clusters + 1)):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "        silhouette_avg = silhouette_score(data, cluster_labels)\n",
    "        \n",
    "        # Armazenar o resultado da silhueta média\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        resultsDf.loc[i] = [k, silhouette_avg] \n",
    "    \n",
    "    indice_melhor_k = np.argmax(silhouette_scores)  \n",
    "    return resultsDf.iloc[indice_melhor_k][\"qtd_clusters\"],indice_melhor_k, resultsDf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42269a77-df39-4b8b-908d-a4365412f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o conjunto de dados para avaliação do método de silhueta\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "\n",
    "melhor_k,indice_melhor_k, resultsDf = silhouette_score_method(dados,\n",
    "                                                            min_clusters=MIN_CLUSTERS,\n",
    "                                                            max_clusters=MAX_CLUSTERS)\n",
    "\n",
    "# Plotagem dos resultados\n",
    "sns.lineplot(x=resultsDf[\"qtd_clusters\"], y=resultsDf[\"silhouette_score\"], marker='o')\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score para K-means')\n",
    "plt.axvline(x=melhor_k, color='red', linestyle='--', label=f'Número ideal de clusters: {melhor_k}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Imprime o número ideal de clusters e os Silhouette Scores\n",
    "print(\"Número ideal de clusters:\", melhor_k)\n",
    "print(\"Silhouette Scores:\\n\", resultsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a4e73-8498-41cb-9572-03241024ebba",
   "metadata": {},
   "source": [
    "### Utilização do Método Calinski-Harabasz Index para determinar o número ótimo de clusters\n",
    "\n",
    "O índice de Calinski-Harabasz é uma métrica interna que avalia a qualidade dos clusters formados por um algoritmo de clustering, como o K-means. \n",
    "Ele calcula a razão entre a dispersão intra-cluster e a dispersão inter-cluster. \n",
    "Quanto maior o valor do índice de Calinski-Harabasz, melhor a separação entre os clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3641e-a84d-4fac-9791-79423f15f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calinski_harabasz_index_method(data,min_clusters=3,max_clusters=10):\n",
    "    \"\"\"\n",
    "    Implementação do índice de Calinski-Harabasz para determinar o número ideal de clusters usando K-means.\n",
    "    \n",
    "    Params:\n",
    "        data: ndarray de forma (n_samples, n_features)\n",
    "            O conjunto de dados a ser agrupado.\n",
    "        min_clusters: int, opcional (padrão=3)\n",
    "            O número mínimo de clusters a serem testados.\n",
    "        max_clusters: int, opcional (padrão=10)\n",
    "            O número máximo de clusters a serem testados.\n",
    "    \n",
    "    Return:\n",
    "        best_k: int\n",
    "            O número ideal de clusters com base no índice de Calinski-Harabasz.\n",
    "        calinski_scores: list\n",
    "            Lista contendo os índices de Calinski-Harabasz para cada número de clusters testado.\n",
    "    \"\"\"\n",
    "    calinski_scores = []\n",
    "    resultsDf = pd.DataFrame({'qtd_clusters':[], 'calinski_score':[]})\n",
    "    \n",
    "    for i,k in enumerate(range(min_clusters, max_clusters + 1)):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "        calinski_score = calinski_harabasz_score(data, cluster_labels)\n",
    "        \n",
    "        # Armazenar o resultado dos scores\n",
    "        calinski_scores.append(calinski_score)\n",
    "        resultsDf.loc[i] = [k, calinski_score] \n",
    "    \n",
    "    indice_melhor_k = np.argmax(calinski_scores) \n",
    "    return resultsDf.iloc[indice_melhor_k][\"qtd_clusters\"],indice_melhor_k, resultsDf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fe17f-e98c-4fcf-ac62-1fe854d0cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o conjunto de dados para avaliação do método de silhueta\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "\n",
    "melhor_k,indice_melhor_k, resultsDf = calinski_harabasz_index_method(dados,MIN_CLUSTERS,MAX_CLUSTERS)\n",
    "\n",
    "# Plotagem dos resultados\n",
    "sns.lineplot(x=resultsDf[\"qtd_clusters\"], y=resultsDf[\"calinski_score\"], marker='o')\n",
    "\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Índice de Calinski-Harabasz')\n",
    "plt.title('Índice de Calinski-Harabasz para K-means')\n",
    "plt.axvline(x=melhor_k, color='red', linestyle='--', label=f'Número ideal de clusters: {melhor_k}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Imprime o número ideal de clusters e os índices de Calinski-Harabasz\n",
    "print(\"Número ideal de clusters:\", melhor_k)\n",
    "print(\"Índices de Calinski-Harabasz:\\n\", resultsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b70419-f74a-4ad3-91b3-42101514032d",
   "metadata": {},
   "source": [
    "### Utilização do Davies Bauldin Index para determinar o número ótimo de clusters\n",
    "\n",
    "O Índice Davies-Bouldin é uma métrica interna usada para avaliar a qualidade dos clusters em um algoritmo de clustering. \n",
    "Ele é calculado como a média do grau de similaridade entre cada cluster e seu cluster mais próximo, onde um índice menor indica uma melhor separação entre os clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478003e8-0dee-4be6-8d67-37e3f5803af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_index_method(data, min_clusters=3,max_clusters=10):\n",
    "    \"\"\"\n",
    "    Implementação do Índice Davies-Bouldin para determinar o número ideal de clusters usando K-means.\n",
    "    \n",
    "    Params:\n",
    "        data: ndarray de forma (n_samples, n_features)\n",
    "            O conjunto de dados a ser agrupado.\n",
    "        max_clusters: int, opcional (padrão=10)\n",
    "            O número máximo de clusters a serem testados.\n",
    "    \n",
    "    Return:\n",
    "        best_k: int\n",
    "            O número ideal de clusters com base no Índice Davies-Bouldin.\n",
    "        davies_bouldin_scores: list\n",
    "            Lista contendo os Índices Davies-Bouldin para cada número de clusters testado.\n",
    "    \"\"\"\n",
    "    davies_bouldin_scores = []\n",
    "    resultsDf = pd.DataFrame({'qtd_clusters':[], 'davies_bouldin_score':[]})\n",
    "    for i,k in enumerate(range(min_clusters, max_clusters + 1)):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "        davies_bouldin_score_value = davies_bouldin_score(data, cluster_labels)\n",
    "\n",
    "        # Armazenar o resultado dos scores\n",
    "        davies_bouldin_scores.append(davies_bouldin_score_value)\n",
    "        resultsDf.loc[i] = [k, davies_bouldin_score_value] \n",
    "    \n",
    "    indice_melhor_k = np.argmin(davies_bouldin_scores) \n",
    "    return resultsDf.iloc[indice_melhor_k][\"qtd_clusters\"],indice_melhor_k, resultsDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b869ff7-41ca-4722-a5d7-e886d1dd4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o conjunto de dados para avaliação do método de silhueta\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "\n",
    "melhor_k,indice_melhor_k, resultsDf = davies_bouldin_index_method(dados,MIN_CLUSTERS,MAX_CLUSTERS)\n",
    "\n",
    "# Plotagem dos resultados\n",
    "sns.lineplot(x=resultsDf[\"qtd_clusters\"], y=resultsDf[\"davies_bouldin_score\"], marker='o')\n",
    "\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Índice Davies-Bouldin')\n",
    "plt.title('Índice Davies-Bouldin para K-means')\n",
    "plt.axvline(x=melhor_k, color='red', linestyle='--', label='Número ideal de clusters: {}'.format(melhor_k))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Imprime o número ideal de clusters e os Índices Davies-Bouldin\n",
    "print(\"Número ideal de clusters:\", melhor_k)\n",
    "print(\"Índices Davies-Bouldin: \\n\", resultsDf[\"davies_bouldin_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4bcb0-d0e2-4b36-b11d-82d612b2d5cf",
   "metadata": {},
   "source": [
    "### Comparação dos métodos para definição do número ótimo de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d184c4-6768-4541-971f-13e606d4876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o conjunto de dados para avaliação do método de silhueta\n",
    "# Excluir coluna do identificador censitário\n",
    "dados=dfArquivo.drop([\"Census tract\"],axis=1)\n",
    "\n",
    "resultadosMetodos=pd.DataFrame({'metodo':[] ,'qtd_clusters':[]})\n",
    "\n",
    "res_gap_stats = gap_statistic_method(dados.values,\n",
    "                                  min_clusters=MIN_CLUSTERS,\n",
    "                                  max_clusters=MAX_CLUSTERS)\n",
    "res_elbow = elbow_method(dados,MIN_CLUSTERS,MAX_CLUSTERS)\n",
    "res_calinski=calinski_harabasz_index_method(dados,MIN_CLUSTERS,MAX_CLUSTERS)\n",
    "res_davies= davies_bouldin_index_method(dados,MIN_CLUSTERS,MAX_CLUSTERS)\n",
    "res_silhouett=silhouette_score_method(dados,MIN_CLUSTERS,MAX_CLUSTERS)\n",
    "\n",
    "resultadosMetodos.loc[len(resultadosMetodos.index)] = ['Gap Statistc',res_gap_stats[0] ] \n",
    "resultadosMetodos.loc[len(resultadosMetodos.index)] = ['Elbow',res_elbow[0] ]  \n",
    "resultadosMetodos.loc[len(resultadosMetodos.index)] = ['Calinski',res_calinski[0] ]  \n",
    "resultadosMetodos.loc[len(resultadosMetodos.index)] = ['Davies',res_davies[0] ]  \n",
    "resultadosMetodos.loc[len(resultadosMetodos.index)] = ['Silhouette',res_silhouett[0] ]  \n",
    "\n",
    "\n",
    "resultadosMetodos[\"qtd_clusters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac7be7-f948-4f5d-9cb6-258ca56cad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=resultadosMetodos, \n",
    "    kind=\"bar\",\n",
    "    x=\"metodo\", \n",
    "    y=\"qtd_clusters\", palette=\"tab10\",hue=\"metodo\"\n",
    ")\n",
    "\n",
    "g.set_axis_labels(\"Método\", \"Qtd. Clusters\")\n",
    "\n",
    "plt.gca().set_yticks([])\n",
    "plt.title(\"Avaliacão métodos definição melhor número de Clusters\\n\")\n",
    "\n",
    "for i,k in enumerate(resultadosMetodos[\"qtd_clusters\"]):\n",
    "    plt.text(i, k + 0.1, str(int(k)), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c107e1-e141-4e82-baa4-8b57e851799a",
   "metadata": {},
   "source": [
    "### Avaliação da qualidade dos agrupamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a1507-6d08-435e-9451-0704da362706",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "resultsDf = pd.DataFrame({'qtd_clusters':[], 'silhouette_score':[]})\n",
    "\n",
    "classificacao=[]\n",
    "silhuetas=[]\n",
    "\n",
    "for i,k in enumerate([2,8,13]):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(dados)\n",
    "    silhouette_avg = silhouette_score(dados, cluster_labels)\n",
    "    ss = silhouette_samples(dados, cluster_labels)\n",
    "    \n",
    "    # Armazenar o resultado da silhueta média\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    classificacao.append(cluster_labels)\n",
    "    silhuetas.append(ss)\n",
    "    resultsDf.loc[i] = [k, silhouette_avg] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec371e-d465-42c7-84b2-b5249d56bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotagem dos resultados\n",
    "sns.barplot(x=resultsDf[\"qtd_clusters\"], y=resultsDf[\"silhouette_score\"])\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score para K-means')\n",
    "#plt.axvline(x=melhor_k, color='red', linestyle='--', label=f'Número ideal de clusters: {melhor_k}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Imprime o número ideal de clusters e os Silhouette Scores\n",
    "print(\"Número ideal de clusters:\", melhor_k)\n",
    "print(\"Silhouette Scores:\\n\", resultsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d8a58-459a-4f5a-b10a-b6479d19a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotulos_silhuetas = pd.DataFrame({'arranjo':[],'rotulo':[], 'silhouette_score':[]})\n",
    "for i in range(len(classificacao)):\n",
    "    for j in range(len(classificacao[i])):\n",
    "        rotulos_silhuetas.loc[len(rotulos_silhuetas.index)]=[int(i)+1,int(classificacao[i][j]),silhuetas[i][j]]\n",
    "    \n",
    "# rotulos_silhuetas.sort_values([\"arranjo\",\"rotulo\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9f068-a74a-471c-adbd-2215eb6a6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rotulos_silhuetas[rotulos_silhuetas[\"arranjo\"]!=4] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c3626-302b-41d7-876a-a7b2e961f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "g = sns.FacetGrid(rotulos_silhuetas, col=\"arranjo\")\n",
    "g.map(sns.histplot, \"silhouette_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81947a-8757-474e-b009-2a77df550d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
